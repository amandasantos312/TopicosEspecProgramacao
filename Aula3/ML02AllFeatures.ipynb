{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8532dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc64fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset: Iris (binário) ===\n",
      "Classes: 0 = virginica (negativa), 1 = versicolor (positiva)\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Instâncias totais: 100 | Nº de features: 4\n",
      "\n",
      "=== 10 primeiras linhas ===\n",
      " sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)                classe\n",
      "               7.0               3.2                4.7               1.4 versicolor (positiva)\n",
      "               6.4               3.2                4.5               1.5 versicolor (positiva)\n",
      "               6.9               3.1                4.9               1.5 versicolor (positiva)\n",
      "               5.5               2.3                4.0               1.3 versicolor (positiva)\n",
      "               6.5               2.8                4.6               1.5 versicolor (positiva)\n",
      "               5.7               2.8                4.5               1.3 versicolor (positiva)\n",
      "               6.3               3.3                4.7               1.6 versicolor (positiva)\n",
      "               4.9               2.4                3.3               1.0 versicolor (positiva)\n",
      "               6.6               2.9                4.6               1.3 versicolor (positiva)\n",
      "               5.2               2.7                3.9               1.4 versicolor (positiva)\n",
      "\n",
      "Distribuição por classe (total):\n",
      "  classe 0 = virginica (negativa)   -> 50\n",
      "  classe 1 = versicolor (positiva)  -> 50\n",
      "\n",
      "Tamanhos -> treino: 70 | teste: 30\n",
      "\n",
      "=== Desempenho no TESTE ===\n",
      "Acurácia: 0.967\n",
      "Precisão (positiva=versicolor): 1.000\n",
      "Recall   (positiva=versicolor): 0.933\n",
      "F1       (positiva=versicolor): 0.966\n",
      "\n",
      "Matriz de Confusão (linhas=Real, colunas=Previsto):\n",
      "           Prev 0  Prev 1\n",
      "Real 0  |    15       0   <- virginica (0)\n",
      "Real 1  |     1      14   <- versicolor (1)\n",
      "\n",
      "Relatório por classe:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   virginica       0.94      1.00      0.97        15\n",
      "  versicolor       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "=== Predições Individuais ===\n",
      "Entrada [np.float64(5.8), np.float64(2.8), np.float64(4.6), np.float64(1.4)] -> prev=versicolor (1) | P(virginica)= 0.159 | P(versicolor)= 0.841\n",
      "Entrada [np.float64(6.3), np.float64(3.0), np.float64(5.8), np.float64(2.2)] -> prev=virginica (0) | P(virginica)= 0.992 | P(versicolor)= 0.008\n",
      "Entrada [np.float64(6.0), np.float64(2.9), np.float64(4.5), np.float64(1.5)] -> prev=versicolor (1) | P(virginica)= 0.161 | P(versicolor)= 0.839\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Classificação Binária – Iris (todas as 4 features)\n",
    "# Versicolor (1, classe positiva) vs Virginica (0, classe negativa)\n",
    "# Modelo: Regressão Logística (com StandardScaler)\n",
    "# Saídas:\n",
    "#   - visão do dataset + 10 primeiras linhas\n",
    "#   - métricas (acc/prec/recall/F1) e matriz de confusão no TESTE\n",
    "#   - predições individuais com probabilidades\n",
    "#   - interpretação via coeficientes da RL\n",
    "# ===============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, classification_report\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.30\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) Carregar Iris e tornar BINÁRIA: 1=versicolor, 0=virginica\n",
    "# ---------------------------------------------------------------\n",
    "iris = load_iris()\n",
    "X_full = iris.data            # (150, 4): [sepal len, sepal wid, petal len, petal wid]\n",
    "y_full = iris.target          # 0=setosa, 1=versicolor, 2=virginica\n",
    "\n",
    "# Filtrar: remover setosa (0). Ficam rótulos 1 e 2 → mapear para {1:1, 2:0}\n",
    "mask = (y_full != 0)\n",
    "X = X_full[mask]\n",
    "y = (y_full[mask] == 1).astype(int)  # versicolor → 1 (positiva), virginica → 0\n",
    "\n",
    "feature_names = iris.feature_names  # usaremos TODAS as 4 features\n",
    "class_map = {0: \"virginica (negativa)\", 1: \"versicolor (positiva)\"}\n",
    "\n",
    "print(\"=== Dataset: Iris (binário) ===\")\n",
    "print(\"Classes: 0 = virginica (negativa), 1 = versicolor (positiva)\")\n",
    "print(\"Features:\", list(feature_names))\n",
    "print(f\"Instâncias totais: {X.shape[0]} | Nº de features: {X.shape[1]}\")\n",
    "\n",
    "# Mostrar as 10 primeiras linhas (features)\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"classe\"] = [class_map[c] for c in y]\n",
    "print(\"\\n=== 10 primeiras linhas ===\")\n",
    "print(df.head(10).to_string(index=False))\n",
    "\n",
    "# Distribuição global das classes\n",
    "vals, cnts = np.unique(y, return_counts=True)\n",
    "print(\"\\nDistribuição por classe (total):\")\n",
    "for v, c in zip(vals, cnts):\n",
    "    print(f\"  classe {v} = {class_map[v]:<22s} -> {c}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2) Split treino/teste (estratificado preserva proporções)\n",
    "# ---------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(f\"\\nTamanhos -> treino: {X_train.shape[0]} | teste: {X_test.shape[0]}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Pipeline: padronização + Regressão Logística\n",
    "# ---------------------------------------------------------------\n",
    "# Por que padronizar?\n",
    "# - A RL otimiza uma função que converge melhor quando as features têm escala similar.\n",
    "# - Coeficientes ficam em escalas comparáveis (ajuda na interpretação relativa).\n",
    "modelo = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4) Treinar\n",
    "# ---------------------------------------------------------------\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5) Avaliar no TESTE\n",
    "# ---------------------------------------------------------------\n",
    "y_pred = modelo.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  # linhas = Real, colunas = Previsto\n",
    "\n",
    "acc  = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, pos_label=1)  # positiva = versicolor\n",
    "rec  = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1   = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"\\n=== Desempenho no TESTE ===\")\n",
    "print(f\"Acurácia: {acc:.3f}\")\n",
    "print(f\"Precisão (positiva=versicolor): {prec:.3f}\")\n",
    "print(f\"Recall   (positiva=versicolor): {rec:.3f}\")\n",
    "print(f\"F1       (positiva=versicolor): {f1:.3f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusão (linhas=Real, colunas=Previsto):\")\n",
    "print(\"           Prev 0  Prev 1\")\n",
    "print(f\"Real 0  |   {cm[0,0]:>3}     {cm[0,1]:>3}   <- virginica (0)\")\n",
    "print(f\"Real 1  |   {cm[1,0]:>3}     {cm[1,1]:>3}   <- versicolor (1)\")\n",
    "\n",
    "print(\"\\nRelatório por classe:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"virginica\", \"versicolor\"]))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 6) Predições individuais (com 4 features)\n",
    "# ---------------------------------------------------------------\n",
    "# Ordem das features: [sepal length, sepal width, petal length, petal width]\n",
    "amostras = np.array([\n",
    "    [5.8, 2.8, 4.6, 1.4],  # geralmente mais versicolor\n",
    "    [6.3, 3.0, 5.8, 2.2],  # geralmente mais virginica\n",
    "    [6.0, 2.9, 4.5, 1.5]   # ponto “fronteira” para ver probabilidade\n",
    "])\n",
    "\n",
    "probas = modelo.predict_proba(amostras)  # colunas: [P(0), P(1)]\n",
    "preds  = modelo.predict(amostras)\n",
    "\n",
    "print(\"=== Predições Individuais ===\")\n",
    "for x, p, pred in zip(amostras, probas, preds):\n",
    "    print(f\"Entrada {list(x)} -> prev={'versicolor (1)' if pred==1 else 'virginica (0)'} \"\n",
    "          f\"| P(virginica)= {p[0]:.3f} | P(versicolor)= {p[1]:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
