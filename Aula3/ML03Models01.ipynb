{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b243e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset: Iris (binário) ===\n",
      "Classes: 0 = virginica (negativa), 1 = versicolor (positiva)\n",
      "Features (usaremos TODAS): ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Instâncias totais: 100 | Nº de features: 4\n",
      "\n",
      "=== 10 primeiras linhas ===\n",
      " sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)         classe\n",
      "               7.0               3.2                4.7               1.4 versicolor (1)\n",
      "               6.4               3.2                4.5               1.5 versicolor (1)\n",
      "               6.9               3.1                4.9               1.5 versicolor (1)\n",
      "               5.5               2.3                4.0               1.3 versicolor (1)\n",
      "               6.5               2.8                4.6               1.5 versicolor (1)\n",
      "               5.7               2.8                4.5               1.3 versicolor (1)\n",
      "               6.3               3.3                4.7               1.6 versicolor (1)\n",
      "               4.9               2.4                3.3               1.0 versicolor (1)\n",
      "               6.6               2.9                4.6               1.3 versicolor (1)\n",
      "               5.2               2.7                3.9               1.4 versicolor (1)\n",
      "\n",
      "Tamanhos -> treino: 70 | teste: 30\n",
      "\n",
      "=== SVM (RBF) ===\n",
      "Acurácia: 1.000\n",
      "Precisão (positiva=versicolor): 1.000\n",
      "Recall   (positiva=versicolor): 1.000\n",
      "F1       (positiva=versicolor): 1.000\n",
      "\n",
      "Matriz de Confusão (linhas=Real, colunas=Previsto):\n",
      "           Prev 0  Prev 1\n",
      "Real 0  |    15       0   <- virginica (0)\n",
      "Real 1  |     0      15   <- versicolor (1)\n",
      "\n",
      "=== Predições Individuais — SVM (RBF) ===\n",
      "Entrada [np.float64(5.8), np.float64(2.8), np.float64(4.6), np.float64(1.4)] -> prev=versicolor (1) | P(virginica)= 0.074 | P(versicolor)= 0.926\n",
      "Entrada [np.float64(6.3), np.float64(3.0), np.float64(5.8), np.float64(2.2)] -> prev=virginica (0) | P(virginica)= 0.994 | P(versicolor)= 0.006\n",
      "Entrada [np.float64(6.0), np.float64(2.9), np.float64(4.5), np.float64(1.5)] -> prev=versicolor (1) | P(virginica)= 0.051 | P(versicolor)= 0.949\n",
      "\n",
      "=== SVM (Linear) ===\n",
      "Acurácia: 1.000\n",
      "Precisão (positiva=versicolor): 1.000\n",
      "Recall   (positiva=versicolor): 1.000\n",
      "F1       (positiva=versicolor): 1.000\n",
      "\n",
      "Matriz de Confusão (linhas=Real, colunas=Previsto):\n",
      "           Prev 0  Prev 1\n",
      "Real 0  |    15       0   <- virginica (0)\n",
      "Real 1  |     0      15   <- versicolor (1)\n",
      "\n",
      "=== Predições Individuais — SVM (Linear) ===\n",
      "Entrada [np.float64(5.8), np.float64(2.8), np.float64(4.6), np.float64(1.4)] -> prev=versicolor (1) (modelo não fornece probabilidade)\n",
      "Entrada [np.float64(6.3), np.float64(3.0), np.float64(5.8), np.float64(2.2)] -> prev=virginica (0) (modelo não fornece probabilidade)\n",
      "Entrada [np.float64(6.0), np.float64(2.9), np.float64(4.5), np.float64(1.5)] -> prev=versicolor (1) (modelo não fornece probabilidade)\n",
      "\n",
      "=== k-NN (k=5) ===\n",
      "Acurácia: 0.967\n",
      "Precisão (positiva=versicolor): 1.000\n",
      "Recall   (positiva=versicolor): 0.933\n",
      "F1       (positiva=versicolor): 0.966\n",
      "\n",
      "Matriz de Confusão (linhas=Real, colunas=Previsto):\n",
      "           Prev 0  Prev 1\n",
      "Real 0  |    15       0   <- virginica (0)\n",
      "Real 1  |     1      14   <- versicolor (1)\n",
      "\n",
      "=== Predições Individuais — k-NN (k=5) ===\n",
      "Entrada [np.float64(5.8), np.float64(2.8), np.float64(4.6), np.float64(1.4)] -> prev=versicolor (1) | P(virginica)= 0.000 | P(versicolor)= 1.000\n",
      "Entrada [np.float64(6.3), np.float64(3.0), np.float64(5.8), np.float64(2.2)] -> prev=virginica (0) | P(virginica)= 1.000 | P(versicolor)= 0.000\n",
      "Entrada [np.float64(6.0), np.float64(2.9), np.float64(4.5), np.float64(1.5)] -> prev=versicolor (1) | P(virginica)= 0.000 | P(versicolor)= 1.000\n",
      "\n",
      "=== MLP (Rede Neural) ===\n",
      "Acurácia: 0.467\n",
      "Precisão (positiva=versicolor): 0.467\n",
      "Recall   (positiva=versicolor): 0.467\n",
      "F1       (positiva=versicolor): 0.467\n",
      "\n",
      "Matriz de Confusão (linhas=Real, colunas=Previsto):\n",
      "           Prev 0  Prev 1\n",
      "Real 0  |     7       8   <- virginica (0)\n",
      "Real 1  |     8       7   <- versicolor (1)\n",
      "\n",
      "=== Predições Individuais — MLP (Rede Neural) ===\n",
      "Entrada [np.float64(5.8), np.float64(2.8), np.float64(4.6), np.float64(1.4)] -> prev=virginica (0) | P(virginica)= 0.617 | P(versicolor)= 0.383\n",
      "Entrada [np.float64(6.3), np.float64(3.0), np.float64(5.8), np.float64(2.2)] -> prev=versicolor (1) | P(virginica)= 0.441 | P(versicolor)= 0.559\n",
      "Entrada [np.float64(6.0), np.float64(2.9), np.float64(4.5), np.float64(1.5)] -> prev=virginica (0) | P(virginica)= 0.545 | P(versicolor)= 0.455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Classificação Binária – Iris (todas as 4 features)\n",
    "# Versicolor (1, classe positiva) vs Virginica (0, classe negativa)\n",
    "# Modelos testados (sem árvore):\n",
    "#   1) SVM (RBF)\n",
    "#   2) SVM (Linear)\n",
    "#   3) k-NN\n",
    "#   4) MLP (rede neural)\n",
    "#\n",
    "# Saídas por modelo:\n",
    "#   - métricas no TESTE (acc, precisão, recall, F1)\n",
    "#   - matriz de confusão\n",
    "#   - predições individuais (probabilidades quando disponíveis)\n",
    "# ===============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, classification_report\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.30\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) Carregar Iris e tornar BINÁRIA: 1=versicolor (positiva), 0=virginica\n",
    "# ---------------------------------------------------------------\n",
    "iris = load_iris()\n",
    "X_full = iris.data            # (150, 4): sepal len, sepal wid, petal len, petal wid\n",
    "y_full = iris.target          # 0=setosa, 1=versicolor, 2=virginica\n",
    "\n",
    "mask = (y_full != 0)          # remove 'setosa'\n",
    "X = X_full[mask]\n",
    "y = (y_full[mask] == 1).astype(int)  # versicolor -> 1, virginica -> 0\n",
    "\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "print(\"=== Dataset: Iris (binário) ===\")\n",
    "print(\"Classes: 0 = virginica (negativa), 1 = versicolor (positiva)\")\n",
    "print(\"Features (usaremos TODAS):\", list(feature_names))\n",
    "print(f\"Instâncias totais: {X.shape[0]} | Nº de features: {X.shape[1]}\\n\")\n",
    "\n",
    "# Amostra dos 10 primeiros registros (para os alunos verem a cara dos dados)\n",
    "df_demo = pd.DataFrame(X, columns=feature_names)\n",
    "df_demo[\"classe\"] = np.where(y==1, \"versicolor (1)\", \"virginica (0)\")\n",
    "print(\"=== 10 primeiras linhas ===\")\n",
    "print(df_demo.head(10).to_string(index=False))\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2) Split treino/teste (estratificado preserva a proporção das classes)\n",
    "# ---------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(f\"Tamanhos -> treino: {X_train.shape[0]} | teste: {X_test.shape[0]}\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Definir os 4 modelos (todos com StandardScaler antes do classificador)\n",
    "# ---------------------------------------------------------------\n",
    "modelos = [\n",
    "    (\"SVM (RBF)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"rbf\", gamma=\"scale\", C=1.0,\n",
    "                    probability=True, random_state=RANDOM_STATE))\n",
    "    ])),\n",
    "    (\"SVM (Linear)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        # LinearSVC não fornece probability; focamos em decisão por hiperplano\n",
    "        (\"clf\", LinearSVC(C=1.0, random_state=RANDOM_STATE))\n",
    "    ])),\n",
    "    (\"k-NN (k=5)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier(n_neighbors=5))\n",
    "    ])),\n",
    "    (\"MLP (Rede Neural)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        # uma camada escondida pequena (8) para didática, com early stopping\n",
    "        (\"clf\", MLPClassifier(hidden_layer_sizes=(8,),\n",
    "                              activation=\"relu\",\n",
    "                              solver=\"adam\",\n",
    "                              max_iter=1000,\n",
    "                              random_state=RANDOM_STATE,\n",
    "                              early_stopping=True))\n",
    "    ])),\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4) Funções utilitárias\n",
    "# ---------------------------------------------------------------\n",
    "def avaliar_modelo(nome, modelo, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Treina o modelo, faz previsões no TESTE e imprime:\n",
    "    - Acurácia, Precisão (positiva=1), Recall (positiva=1), F1\n",
    "    - Matriz de confusão\n",
    "    Retorna o modelo treinado.\n",
    "    \"\"\"\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)   # linhas = Real, colunas = Previsto\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, pos_label=1)\n",
    "    rec  = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1   = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    print(f\"=== {nome} ===\")\n",
    "    print(f\"Acurácia: {acc:.3f}\")\n",
    "    print(f\"Precisão (positiva=versicolor): {prec:.3f}\")\n",
    "    print(f\"Recall   (positiva=versicolor): {rec:.3f}\")\n",
    "    print(f\"F1       (positiva=versicolor): {f1:.3f}\")\n",
    "    print(\"\\nMatriz de Confusão (linhas=Real, colunas=Previsto):\")\n",
    "    print(\"           Prev 0  Prev 1\")\n",
    "    print(f\"Real 0  |   {cm[0,0]:>3}     {cm[0,1]:>3}   <- virginica (0)\")\n",
    "    print(f\"Real 1  |   {cm[1,0]:>3}     {cm[1,1]:>3}   <- versicolor (1)\\n\")\n",
    "    return modelo\n",
    "\n",
    "def predicoes_individuais(nome, modelo, exemplos):\n",
    "    \"\"\"\n",
    "    Mostra predições individuais com probabilidades quando o modelo oferece.\n",
    "    \"\"\"\n",
    "    print(f\"=== Predições Individuais — {nome} ===\")\n",
    "    if hasattr(modelo, \"predict_proba\"):\n",
    "        probas = modelo.predict_proba(exemplos)   # colunas: [P(0), P(1)]\n",
    "        preds  = modelo.predict(exemplos)\n",
    "        for x, p, pred in zip(exemplos, probas, preds):\n",
    "            print(f\"Entrada {list(x)} -> prev={'versicolor (1)' if pred==1 else 'virginica (0)'} \"\n",
    "                  f\"| P(virginica)= {p[0]:.3f} | P(versicolor)= {p[1]:.3f}\")\n",
    "    else:\n",
    "        # Ex.: LinearSVC não tem predict_proba\n",
    "        preds = modelo.predict(exemplos)\n",
    "        for x, pred in zip(exemplos, preds):\n",
    "            print(f\"Entrada {list(x)} -> prev={'versicolor (1)' if pred==1 else 'virginica (0)'} \"\n",
    "                  f\"(modelo não fornece probabilidade)\")\n",
    "    print()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5) Rodar os 4 modelos\n",
    "# ---------------------------------------------------------------\n",
    "treinados = []\n",
    "for nome, mdl in modelos:\n",
    "    mfit = avaliar_modelo(nome, mdl, X_train, y_train, X_test, y_test)\n",
    "    treinados.append((nome, mfit))\n",
    "\n",
    "    # Três exemplos com TODAS as 4 features (ordem: sepal len, sepal wid, petal len, petal wid)\n",
    "    exemplos = np.array([\n",
    "        [5.8, 2.8, 4.6, 1.4],  # tende a versicolor\n",
    "        [6.3, 3.0, 5.8, 2.2],  # tende a virginica\n",
    "        [6.0, 2.9, 4.5, 1.5]   # perto da fronteira\n",
    "    ])\n",
    "    predicoes_individuais(nome, mfit, exemplos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
