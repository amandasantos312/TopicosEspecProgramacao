{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset: Covertype (binário) ===\n",
      "Instâncias totais: 581012 | Nº de features: 54\n",
      "\n",
      "Tamanhos -> treino: 406708 | teste: 174304\n",
      "\n",
      "--- Treinando: SVM (Linear) ---\n",
      "=== SVM (Linear) ===\n",
      "Tempo de execução: 27.30 segundos\n",
      "Acurácia: 0.769\n",
      "Precisão (positiva=Spruce/Fir): 0.693\n",
      "Recall   (positiva=Spruce/Fir): 0.655\n",
      "F1       (positiva=Spruce/Fir): 0.674\n",
      "\n",
      "Matriz de Confusão (linhas=Real, colunas=Previsto):\n",
      "           Prev 0    Prev 1\n",
      "Real 0  |    92352     18400   <- Outras (0)\n",
      "Real 1  |    21927     41625   <- Spruce/Fir (1)\n",
      "\n",
      "--- Predições Individuais — SVM (Linear) ---\n",
      "Amostra 219718 -> prev=Outras (0) (modelo não fornece probabilidade)\n",
      "Amostra 68526 -> prev=Outras (0) (modelo não fornece probabilidade)\n",
      "Amostra 520898 -> prev=Spruce/Fir (1) (modelo não fornece probabilidade)\n",
      "\n",
      "============================================================\n",
      "--- Treinando: k-NN (k=5) ---\n"
     ]
    }
   ],
   "source": [
    "# =============================================================== \n",
    "# Classificação Binária: Spruce/Fir (1) vs. Outras (0)\n",
    "# Foco: Comparar desempenho (acurácia e tempo) de diferentes algoritmos em um dataset grande.\n",
    "# ===============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "\n",
    "# --- CONFIGURAÇÕES GLOBAIS ---\n",
    "# Define uma semente para garantir que os resultados aleatórios sejam sempre os mesmos\n",
    "RANDOM_STATE = 42\n",
    "# Define a proporção do dataset que será usada para teste (30%)\n",
    "TEST_SIZE = 0.30\n",
    "\n",
    "\n",
    "# 1) Carregar e preparar os dados (sem alteração)\n",
    "cov = fetch_covtype(as_frame=True)\n",
    "X = cov.data           #Features\n",
    "y_mult = cov.target    #Target original com 7 classes\n",
    "\n",
    "# Binariza o problema: se a classe for 1 (Spruce/Fir), o valor é 1. Caso contrário, é 0.\n",
    "y = (y_mult == 1).astype(int)\n",
    "\n",
    "# Armazena nomes para uso posterior em relatórios e gráficos\n",
    "feature_names = cov.feature_names\n",
    "class_names = {0: \"Outras (0)\", 1: \"Spruce/Fir (1)\"}\n",
    "\n",
    "print(\"=== Dataset: Covertype (binário) ===\")\n",
    "print(f\"Instâncias totais: {X.shape[0]} | Nº de features: {X.shape[1]}\\n\")\n",
    "\n",
    "\n",
    "# 2) Split treino/teste (sem alteração)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(f\"Tamanhos -> treino: {X_train.shape[0]} | teste: {X_test.shape[0]}\\n\")\n",
    "\n",
    "# 3) Definir os modelos (SVM RBF FOI REMOVIDO/COMENTADO)\n",
    "modelos = [\n",
    "    # (\"SVM (RBF)\", Pipeline([\n",
    "    #     (\"scaler\", StandardScaler()),\n",
    "    #     (\"clf\", SVC(kernel=\"rbf\", gamma=\"scale\", C=1.0,\n",
    "    #                 probability=True, random_state=RANDOM_STATE))\n",
    "    # ])),\n",
    "    (\"SVM (Linear)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LinearSVC(C=1.0, random_state=RANDOM_STATE, max_iter=2000))\n",
    "    ])),\n",
    "    (\"k-NN (k=5)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1))\n",
    "    ])),\n",
    "    (\"MLP (Rede Neural)\", Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", MLPClassifier(hidden_layer_sizes=(64,),\n",
    "                              activation=\"relu\",\n",
    "                              solver=\"adam\",\n",
    "                              max_iter=1000,\n",
    "                              random_state=RANDOM_STATE,\n",
    "                              early_stopping=True))\n",
    "    ])),\n",
    "]\n",
    "\n",
    "# 4) Funções utilitárias (sem alteração)\n",
    "def avaliar_modelo(nome, modelo, X_train, y_train, X_test, y_test):\n",
    "    print(f\"--- Treinando: {nome} ---\")\n",
    "    # Marca o tempo de início\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Treina o modelo com os dados de treino\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Faz previsões nos dados de teste\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Marca o tempo de fim\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calcula as métricas de desempenho\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, pos_label=1)\n",
    "    rec  = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1   = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    # Imprime os resultados formatados\n",
    "    print(f\"=== {nome} ===\")\n",
    "    print(f\"Tempo de execução: {end_time - start_time:.2f} segundos\")\n",
    "    print(f\"Acurácia: {acc:.3f}\")\n",
    "    print(f\"Precisão (positiva=Spruce/Fir): {prec:.3f}\")\n",
    "    print(f\"Recall   (positiva=Spruce/Fir): {rec:.3f}\")\n",
    "    print(f\"F1       (positiva=Spruce/Fir): {f1:.3f}\")\n",
    "    print(\"\\nMatriz de Confusão (linhas=Real, colunas=Previsto):\")\n",
    "    print(\"           Prev 0    Prev 1\")\n",
    "    print(f\"Real 0  |  {cm[0,0]:>7}   {cm[0,1]:>7}   <- {class_names[0]}\")\n",
    "    print(f\"Real 1  |  {cm[1,0]:>7}   {cm[1,1]:>7}   <- {class_names[1]}\\n\")\n",
    "\n",
    "    return modelo\n",
    "\n",
    "def predicoes_individuais(nome, modelo, exemplos):\n",
    "    print(f\"--- Predições Individuais — {nome} ---\")\n",
    "\n",
    "    if hasattr(modelo, \"predict_proba\"):\n",
    "        probas = modelo.predict_proba(exemplos)\n",
    "        preds  = modelo.predict(exemplos)\n",
    "        for i, (p, pred) in enumerate(zip(probas, preds)):\n",
    "            idx = exemplos.index[i]\n",
    "            print(f\"Amostra {idx} -> prev={class_names[pred]} | P(Outras)= {p[0]:.3f} | P(Spruce/Fir)= {p[1]:.3f}\")\n",
    "    else:\n",
    "        # Caso do LinearSVC, que não calcula probabilidades\n",
    "        preds = modelo.predict(exemplos)\n",
    "        for i, pred in enumerate(preds):\n",
    "            idx = exemplos.index[i]\n",
    "            print(f\"Amostra {idx} -> prev={class_names[pred]} (modelo não fornece probabilidade)\")\n",
    "    print()\n",
    "\n",
    "# 5) Rodar os modelos (sem alteração)\n",
    "exemplos = X_test.head(3)\n",
    "\n",
    "# Loop principal: itera sobre cada modelo definido na lista `modelos`\n",
    "for nome, mdl in modelos:\n",
    "    mfit = avaliar_modelo(nome, mdl, X_train, y_train, X_test, y_test)\n",
    "    predicoes_individuais(nome, mfit, exemplos)\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
